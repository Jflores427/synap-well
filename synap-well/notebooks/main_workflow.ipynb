{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc67d497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Josue\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Josue\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ensorflow (C:\\Users\\Josue\\AppData\\Roaming\\Python\\Python312\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%pip install ipynb python-dotenv transformers accelerate bitsandbytes kaggle kagglehub openpyxl transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb8bcfe7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbaa051c9b048b4a8c8b262350b592e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipynb.fs.full.recommendations import *  # Roughly 90 seconds for 8GB VRAM GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c19a835",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipynb.fs.full.emotion_classification_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e27a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipynb.fs.full.completed_log_tracker_feature_extraction.ipynb import *  # Run this file in its original file to produce processed .csv file for Log Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbf9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from ipynb.fs.full.completed_wellness_dataset_feature_extraction import * # Run this file in its original file to produce processed .csv file for wellness_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8451374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Regressor_Predictive_Model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20c3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load your dataset\n",
    "daily_df = pd.read_csv(\"../data/processed/processed_log_tracker.csv\")\n",
    "\n",
    "# Columns that represent the tags\n",
    "tag_columns = [\n",
    "    'activity_level_grouping',\n",
    "    'demographic_health_grouping',\n",
    "    'sleep_health',\n",
    "    'heart_health',\n",
    "    'bp_health',\n",
    "    'stress_profile_grouping',\n",
    "    'social_wellness_grouping'\n",
    "]\n",
    "\n",
    "# Bundle the tags per row and removes any NaN/null values\n",
    "daily_df['tags_per_row'] = daily_df[tag_columns].apply(\n",
    "    lambda row: [tag for tag in row if pd.notna(tag)],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Convert each list of tags into a comma-separated string\n",
    "daily_df['tags_per_row_str'] = daily_df['tags_per_row'].apply(lambda tags: ', '.join(tags))\n",
    "\n",
    "# View the result\n",
    "print(daily_df[['tags_per_row_str']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1100c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "\n",
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face Token\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")\n",
    "\n",
    "#Weather API Token\n",
    "WEATHER_API_KEY = os.getenv(\"WEATHER_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b6df85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Initial Questions csv file into a DataFrame\n",
    "initial_df = pd.read_csv('../data/raw/CS-GY-6923 Log Tracker  - Initial Questions.csv')\n",
    "\n",
    "# Extract the last row of the DataFrame\n",
    "last_updated_entry = initial_df.iloc[-1]\n",
    "\n",
    "# De-structure relevant information from features into variables\n",
    "gender = last_updated_entry['Gender']\n",
    "age = last_updated_entry['Age']\n",
    "height = last_updated_entry['Height']\n",
    "activities = last_updated_entry['Activities for Mental Health (such as therapy sessions or meditation) [Comma separated]']\n",
    "quality_social_interactions = last_updated_entry['Quality or frequency of social interactions']\n",
    "location = last_updated_entry['Location']\n",
    "\n",
    "# print(gender)\n",
    "# print(age)\n",
    "# print(height)\n",
    "# print(activities)\n",
    "# print(quality_social_interactions)\n",
    "# print(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4df5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather Prompt\n",
    "from datetime import datetime\n",
    "\n",
    "def fetch_weather_data(city_name, api_key):\n",
    "    \"\"\"\n",
    "    Fetch current weather description from WeatherAPI for a given city.\n",
    "    \"\"\"\n",
    "    url = f'http://api.weatherapi.com/v1/current.json?key={api_key}&q={city_name}'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        if 'current' in data and 'condition' in data['current']:\n",
    "            return data['current']['condition']['text']\n",
    "        else:\n",
    "            print(\"Warning: Weather data structure is incomplete.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None\n",
    "    \n",
    "def fetch_past_weather_data(city_name, date, api_key):\n",
    "    \"\"\"\n",
    "    Fetch current weather description from WeatherAPI for a given city.\n",
    "    \"\"\"   \n",
    "\n",
    "    raw_date = date  # MM/DD/YYYY format\n",
    "    date_obj = datetime.strptime(raw_date, '%m/%d/%Y')\n",
    "    formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "    \n",
    "    url = f'http://api.weatherapi.com/v1/history.json?key={api_key}&q={city_name}&dt={formatted_date}'\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "\n",
    "        print(data)\n",
    "\n",
    "        if 'forecast' in data and 'forecastday' in data['forecast'] and len(data['forecast']['forecastday']) > 0 and 'day' in data['forecast']['forecastday'][0] and 'condition' in data['forecast']['forecastday'][0]['day']:\n",
    "            return data['forecast']['forecastday'][0]['day']['condition']['text']\n",
    "        else:\n",
    "            print(\"Warning: Weather data structure is incomplete.\")\n",
    "            return None\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching weather data: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def classify_weather_situation(weather_description):\n",
    "    \"\"\"\n",
    "    Classify weather condition into one of: SUNNY, RAINY, CLOUDY, WINDY, or UNKNOWN.\n",
    "    \"\"\"\n",
    "    description = weather_description.lower()\n",
    "\n",
    "    if 'sunny' in description:\n",
    "        return 'SUNNY'\n",
    "    elif 'rain' in description or 'shower' in description:\n",
    "        return 'RAINY'\n",
    "    elif 'overcast' in description or 'cloud' in description:\n",
    "        return 'CLOUDY'\n",
    "    elif 'wind' in description:\n",
    "        return 'WINDY'\n",
    "    else:\n",
    "        return 'UNKNOWN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0f54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferences part of prompt\n",
    "preferences = activities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b9d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resulting Classification probability output from Regressor_Predictive_Model File\n",
    "import torch\n",
    "import time\n",
    "\n",
    "daily_activity_recommendation_list = []\n",
    "\n",
    "features_selected = [\"duration_of_sleep_hours\", \"quality_of_sleep_110\", \"level_of_stress_scale_110\", \"level_of_workload_scale_110\"]\n",
    "regressor_probs_list = Invoke_Regressor(daily_df, features_selected)\n",
    "\n",
    "for index, row in daily_df.iterrows():\n",
    "    if index > 0:\n",
    "        break\n",
    "    notes = row['notes']  # Get the note for this row\n",
    "    date = row['date'] # Get the date for this row\n",
    "    mental_body_state_tags = row['tags_per_row_str']\n",
    "\n",
    "    regressor_probs = torch.Tensor(regressor_probs_list[index])\n",
    "    \n",
    "    # Run the function on each note\n",
    "    result = run_emotion_pipeline(notes, regressor_probs)\n",
    "\n",
    "    # print(\"Emotion Classification Result:\")\n",
    "    # print(f\"  {notes}\")\n",
    "    # print(f\"  Superclass: {result['superclass']}\")\n",
    "    # print(f\"  Sub-emotion: {result['sub_emotion']} ({result['confidence']:.3f})\")\n",
    "    # print(\"  Top 5 Emotions:\")\n",
    "    # for label, prob in result[\"top_5_emotions\"]:\n",
    "    #     print(f\"    - {label}: {prob:.4f}\")\n",
    "\n",
    "    superclass_emotion = result['superclass']\n",
    "    sub_emotion = result['sub_emotion']\n",
    "    mood_string = f\"{superclass_emotion} - {sub_emotion}\"\n",
    "\n",
    "    weather_description = fetch_past_weather_data(location, date, WEATHER_API_KEY) \n",
    "    # time.sleep(1)\n",
    "    weather_situation = classify_weather_situation(weather_description)\n",
    "\n",
    "    daily_recommended_activities= generate_activity_suggestions(mood_string, weather_situation, mental_body_state_tags, preferences)\n",
    "\n",
    "    generated_prompt_parts = daily_recommended_activities.split(\"[/INST]\")\n",
    "\n",
    "    generated_prompt_question = generated_prompt_parts[0]\n",
    "    generated_prompt_answer = generated_prompt_parts[1]\n",
    "    \n",
    "    daily_activity_recommendation_list.append(f\"{generated_prompt_question.split(\".\")[0] + \". \" + generated_prompt_question.split(\".\")[1] }: \\n\"  \n",
    "                                              f\"{generated_prompt_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12abe6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for daily_activity_recommendation in daily_activity_recommendation_list:\n",
    "    print(daily_activity_recommendation)\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
