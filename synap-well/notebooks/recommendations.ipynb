{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a12902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv transformers accelerate bitsandbytes --quiet # Uncomment if running this file directly and needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8320da33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Josue\\CS-GY-6923 Machine Learning\\synap-well\\synap-well\\myenv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d37f8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face Token\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d146905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [01:11<00:00, 35.52s/it]\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", token=HUGGING_FACE_TOKEN)\n",
    "\n",
    "# Load model in 4-bit precision using bitsandbytes\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\",\n",
    "    token=HUGGING_FACE_TOKEN\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample = True,\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda415e",
   "metadata": {},
   "source": [
    "We decided to opt for \"mistralai/Mistral-7B-Instruct-v0.1\" due to the following reasons:\n",
    "1) Very strong instruction following for a 7B model\n",
    "2) Low VRAM usage (for 7B size) — works on 8–16GB GPUs\n",
    "3) Very good speed vs. quality balance\n",
    "\n",
    "As for performance metrics, this model's purpose is for activity recommendation generation, thus other quantitative metrics like BLEU would not be useful. As such, we shall rely on human evaluation as our primary form of quantitive measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9a70a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your prompt and generate activity suggestions function\n",
    "def generate_activity_suggestions(mood, weather, mental_body_state, preferences):\n",
    "    prompt = (\n",
    "        f\"[INST] The user is feeling {mood}, the weather is {weather}, and they are currently in a state of {mental_body_state}. \"\n",
    "        f\"They typically enjoy activities like {preferences}. \"\n",
    "        f\"Based on the weather, user's mood, state, and preferences, suggest 3 relevant activities \"\n",
    "        f\"with a 50-word short description for each one, that would produce a healthy mental well-being in the user. [/INST]\"\n",
    "    )\n",
    "    result = generator(prompt)\n",
    "    return result[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "444c6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activity 1: Rainforest Walk - Take a stroll through an indoor rainforest to get some exercise while also enjoying nature. This activity will help reduce stress levels and improve overall mood.\n",
      "\n",
      "Activity 2: Indoor Yoga Session - Practice yoga indoors to improve flexibility, strength, and relaxation. It can be done alone or with friends, making it perfect for socialization as well.\n",
      "\n",
      "Activity 3: Music Therapy Sessions - Attend a music therapy session where you listen to calming and relaxing music to promote relaxation and reduce stress. It can be done individually or in groups, providing opportunities for social interaction.\n"
     ]
    }
   ],
   "source": [
    "# Example Input\n",
    "mood = \"happy\"\n",
    "weather = \"rainy\"\n",
    "state = \"HEALTHY_CONSUMPTION, POOR_SLEEP, GOOD_HEART_HEALTH, GOOD_BlOOD_PRESSURE, ACTIVE, HIGH_Stress, LOW_Workload, HIGH_SOCIAL\"\n",
    "preferences = \"socializing, listening to music, playing video games, running, hiking\"\n",
    "\n",
    "output = generate_activity_suggestions(mood, weather, state, preferences)\n",
    "output = output.split(\"[/INST]\")[1].strip()\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
