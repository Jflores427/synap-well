{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a12902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install python-dotenv transformers accelerate bitsandbytes --quiet # Uncomment if running this file directly and needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8320da33",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d37f8b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Environment Variables\n",
    "load_dotenv()\n",
    "\n",
    "# Hugging Face Token\n",
    "HUGGING_FACE_TOKEN = os.getenv(\"HUGGING_FACE_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d146905",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae09a6ffd71427db0d79eea22eecb38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\", token=HUGGING_FACE_TOKEN)\n",
    "\n",
    "# Load model in 4-bit precision using bitsandbytes\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.1\",\n",
    "    load_in_4bit=True,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16,\n",
    "    token=HUGGING_FACE_TOKEN\n",
    ")\n",
    "\n",
    "# Create pipeline\n",
    "generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=250,\n",
    "    temperature=0.7,\n",
    "    top_p=0.95,\n",
    "    repetition_penalty=1.2,\n",
    "    do_sample = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfda415e",
   "metadata": {},
   "source": [
    "We decided to opt for \"mistralai/Mistral-7B-Instruct-v0.1\" due to the following reasons:\n",
    "1) Very strong instruction following for a 7B model\n",
    "2) Low VRAM usage (for 7B size) — works on 8–16GB GPUs\n",
    "3) Very good speed vs. quality balance\n",
    "\n",
    "As for performance metrics, this model's purpose is for activity recommendation generation, thus other quantitative metrics like BLEU would not be useful. As such, we shall rely on human evaluation as our primary form of quantitive measure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a70a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your prompt and generate activity suggestions function\n",
    "def generate_activity_suggestions(mood, weather, mental_body_state, preferences):\n",
    "    prompt = (\n",
    "        f\"[INST] The user is feeling {mood}, the weather is {weather}, and they are currently in a state of {mental_body_state}. \"\n",
    "        f\"They typically enjoy activities like {preferences}. \"\n",
    "        f\"Based on the weather, user's mood, state, and preferences, suggest at most 3 relevant (preferably fitness-focused for at least 1 activity) activities \"\n",
    "        f\"with a 50-word short description for each one, that would produce a healthy mental well-being in the user. [/INST]\"\n",
    "    )\n",
    "    result = generator(prompt)\n",
    "    return result[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444c6b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "C:\\Users\\Josue\\AppData\\Roaming\\Python\\Python312\\site-packages\\bitsandbytes\\nn\\modules.py:451: UserWarning: Input type into Linear4bit is torch.float16, but bnb_4bit_compute_dtype=torch.float32 (default). This will lead to slow inference or training speed.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are three fitness-focused activities based on your preferences:\n",
      "\n",
      "1. Running - Enjoy a refreshing jog outside under the warm sunshine. This activity can help you reduce stress, boost mood, and improve cardiovascular health.\n",
      "2. Socializing - Join a group hike or walk through nature. Exercise together while enjoying fresh air and beautiful scenery. This can also increase social connections and decrease stress levels.\n",
      "3. Yoga - Relax after a busy day by practicing yoga indoors or outdoors. It promotes flexibility, strength, balance, and mindfulness, helping to relieve stress and anxiety.\n"
     ]
    }
   ],
   "source": [
    "# Example Input\n",
    "mood = \"happy\"\n",
    "weather = \"sunny\"\n",
    "state = \"HEALTHY_CONSUMPTION, POOR_SLEEP, GOOD_HEART_HEALTH, GOOD_BlOOD_PRESSURE, ACTIVE, HIGH_Stress, LOW_Workload, HIGH_SOCIAL\"\n",
    "preferences = \"socializing, listening to music, playing video games, running, hiking\"\n",
    "\n",
    "output = generate_activity_suggestions(mood, weather, state, preferences)\n",
    "output = output.split(\"[/INST]\")[1]\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
